{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPqyVl4YarNhEmh8qvHn4s9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "51903c50089b48aaa059503816116341": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9bb2c8ad7040458e8f680e1a3227782c",
              "IPY_MODEL_c2393ec16a6a421ebc20337d3181a039",
              "IPY_MODEL_3f4b344b1e2148e29838b5279cecc2cf"
            ],
            "layout": "IPY_MODEL_75c4eaf5824946e09f91eec6d7b3d2d7"
          }
        },
        "9bb2c8ad7040458e8f680e1a3227782c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acfd8c6082de4e4fa22ccdeb4a07fb15",
            "placeholder": "​",
            "style": "IPY_MODEL_0e36ca1085db45dab5a50e56c9e1ee51",
            "value": "ZOO: 100%"
          }
        },
        "c2393ec16a6a421ebc20337d3181a039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2627a22961a6479ba7e78bc71698f34a",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_583b0df0876041b0a13461416db9f4fb",
            "value": 5
          }
        },
        "3f4b344b1e2148e29838b5279cecc2cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1850a6441fa74836a242b9829a8fd7f0",
            "placeholder": "​",
            "style": "IPY_MODEL_36e2ad37f91a473982add3124a13d769",
            "value": " 5/5 [00:03&lt;00:00,  1.58it/s]"
          }
        },
        "75c4eaf5824946e09f91eec6d7b3d2d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acfd8c6082de4e4fa22ccdeb4a07fb15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e36ca1085db45dab5a50e56c9e1ee51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2627a22961a6479ba7e78bc71698f34a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "583b0df0876041b0a13461416db9f4fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1850a6441fa74836a242b9829a8fd7f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36e2ad37f91a473982add3124a13d769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moukouel/Notebooks/blob/main/ARTPlayGround.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Will be using this notebook to test AI security tools"
      ],
      "metadata": {
        "id": "o0oafvNlWGTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install adversarial-robustness-toolbox\n",
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6FZsRjYTLO1",
        "outputId": "f8716a6f-1e62-4fc3-9230-91faf7763c77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting adversarial-robustness-toolbox\n",
            "  Downloading adversarial_robustness_toolbox-1.19.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (1.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (1.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (75.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->adversarial-robustness-toolbox) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->adversarial-robustness-toolbox) (3.6.0)\n",
            "Downloading adversarial_robustness_toolbox-1.19.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: adversarial-robustness-toolbox\n",
            "Successfully installed adversarial-robustness-toolbox-1.19.1\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##\n",
        "The script demonstrates a simple example of using ART with TensorFlow v2.x. The example train a small model on the MNIST\n",
        "dataset and creates adversarial examples using the Fast Gradient Sign Method. Here we use the ART classifier to train\n",
        "the model, it would also be possible to provide a pretrained model to the ART classifier.\n",
        "The parameters are chosen for reduced computational requirements of the script and not optimised for accuracy."
      ],
      "metadata": {
        "id": "v30iYMt-U7ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from art.attacks.evasion import FastGradientMethod\n",
        "from art.estimators.classification import TensorFlowV2Classifier\n",
        "from art.utils import load_mnist"
      ],
      "metadata": {
        "id": "eGlhoWU7UIzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load the MNIST dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test), min_pixel_value, max_pixel_value = load_mnist()"
      ],
      "metadata": {
        "id": "7mdU5nIXUNtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Create the model\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D\n",
        "\n",
        "\n",
        "class TensorFlowModel(Model):\n",
        "    \"\"\"\n",
        "    Standard TensorFlow model for unit testing.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(TensorFlowModel, self).__init__()\n",
        "        self.conv1 = Conv2D(filters=4, kernel_size=5, activation=\"relu\")\n",
        "        self.conv2 = Conv2D(filters=10, kernel_size=5, activation=\"relu\")\n",
        "        self.maxpool = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\", data_format=None)\n",
        "        self.flatten = Flatten()\n",
        "        self.dense1 = Dense(100, activation=\"relu\")\n",
        "        self.logits = Dense(10, activation=\"linear\")\n",
        "\n",
        "    def call(self, x):\n",
        "        \"\"\"\n",
        "        Call function to evaluate the model.\n",
        "\n",
        "        :param x: Input to the model\n",
        "        :return: Prediction of the model\n",
        "        \"\"\"\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense1(x)\n",
        "        x = self.logits(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = TensorFlowModel()\n",
        "loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)"
      ],
      "metadata": {
        "id": "3z9goYskUaNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Create the ART classifier\n",
        "\n",
        "classifier = TensorFlowV2Classifier(\n",
        "    model=model,\n",
        "    loss_object=loss_object,\n",
        "    optimizer=optimizer,\n",
        "    nb_classes=10,\n",
        "    input_shape=(28, 28, 1),\n",
        "    clip_values=(0, 1),\n",
        ")"
      ],
      "metadata": {
        "id": "gevoIO0GUcZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Train the ART classifier\n",
        "\n",
        "classifier.fit(x_train, y_train, batch_size=64, nb_epochs=3)"
      ],
      "metadata": {
        "id": "YFGMQMugUkCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Evaluate the ART classifier on benign test examples\n",
        "\n",
        "predictions = classifier.predict(x_test)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_AfbOqMUoSr",
        "outputId": "2ce3087b-7b86-4263-98b1-958b0ab4d65a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on benign test examples: 97.74000000000001%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Generate adversarial test examples\n",
        "attack = FastGradientMethod(estimator=classifier, eps=0.2)\n",
        "x_test_adv = attack.generate(x=x_test)"
      ],
      "metadata": {
        "id": "o8ICx3TNUtDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Evaluate the ART classifier on adversarial test examples\n",
        "\n",
        "predictions = classifier.predict(x_test_adv)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "print(\"Accuracy on adversarial test examples: {}%\".format(accuracy * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHkP_WaYS7RX",
        "outputId": "5d6c5d8e-9d72-42c2-9126-2133a91428b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on adversarial test examples: 21.73%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "The script demonstrates a simple example of using ART with PyTorch. The example train a small model on the MNIST dataset\n",
        "and creates adversarial examples using the Fast Gradient Sign Method. Here we use the ART classifier to train the model,\n",
        "it would also be possible to provide a pretrained model to the ART classifier.\n",
        "The parameters are chosen for reduced computational requirements of the script and not optimised for accuracy.\n",
        "\"\"\"\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "from art.attacks.evasion import FastGradientMethod\n",
        "from art.estimators.classification import PyTorchClassifier\n",
        "from art.utils import load_mnist\n",
        "\n",
        "\n",
        "# Step 0: Define the neural network model, return logits instead of activation in forward method\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv_1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=5, stride=1)\n",
        "        self.conv_2 = nn.Conv2d(in_channels=4, out_channels=10, kernel_size=5, stride=1)\n",
        "        self.fc_1 = nn.Linear(in_features=4 * 4 * 10, out_features=100)\n",
        "        self.fc_2 = nn.Linear(in_features=100, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv_1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv_2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4 * 4 * 10)\n",
        "        x = F.relu(self.fc_1(x))\n",
        "        x = self.fc_2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Step 1: Load the MNIST dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test), min_pixel_value, max_pixel_value = load_mnist()\n",
        "\n",
        "# Step 1a: Swap axes to PyTorch's NCHW format\n",
        "\n",
        "x_train = np.transpose(x_train, (0, 3, 1, 2)).astype(np.float32)\n",
        "x_test = np.transpose(x_test, (0, 3, 1, 2)).astype(np.float32)\n",
        "\n",
        "# Step 2: Create the model\n",
        "\n",
        "model = Net()\n",
        "\n",
        "# Step 2a: Define the loss function and the optimizer\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Step 3: Create the ART classifier\n",
        "\n",
        "classifier = PyTorchClassifier(\n",
        "    model=model,\n",
        "    clip_values=(min_pixel_value, max_pixel_value),\n",
        "    loss=criterion,\n",
        "    optimizer=optimizer,\n",
        "    input_shape=(1, 28, 28),\n",
        "    nb_classes=10,\n",
        ")\n",
        "\n",
        "# Step 4: Train the ART classifier\n",
        "\n",
        "classifier.fit(x_train, y_train, batch_size=64, nb_epochs=3)\n",
        "\n",
        "# Step 5: Evaluate the ART classifier on benign test examples\n",
        "\n",
        "predictions = classifier.predict(x_test)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))\n",
        "\n",
        "# Step 6: Generate adversarial test examples\n",
        "attack = FastGradientMethod(estimator=classifier, eps=0.2)\n",
        "x_test_adv = attack.generate(x=x_test)\n",
        "\n",
        "# Step 7: Evaluate the ART classifier on adversarial test examples\n",
        "\n",
        "predictions = classifier.predict(x_test_adv)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "print(\"Accuracy on adversarial test examples: {}%\".format(accuracy * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYlHVKnpWOx_",
        "outputId": "e8b8439b-bd66-4bbc-c7d8-45fa067475f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on benign test examples: 97.27%\n",
            "Accuracy on adversarial test examples: 21.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "The script demonstrates a simple example of using ART with scikit-learn. The example train a small model on the MNIST\n",
        "dataset and creates adversarial examples using the Fast Gradient Sign Method. Here we use the ART classifier to train\n",
        "the model, it would also be possible to provide a pretrained model to the ART classifier.\n",
        "The parameters are chosen for reduced computational requirements of the script and not optimised for accuracy.\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "\n",
        "from art.attacks.evasion import FastGradientMethod\n",
        "from art.estimators.classification import SklearnClassifier\n",
        "from art.utils import load_mnist\n",
        "\n",
        "# Step 1: Load the MNIST dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test), min_pixel_value, max_pixel_value = load_mnist()\n",
        "\n",
        "# Step 1a: Flatten dataset\n",
        "\n",
        "nb_samples_train = x_train.shape[0]\n",
        "nb_samples_test = x_test.shape[0]\n",
        "x_train = x_train.reshape((nb_samples_train, 28 * 28))\n",
        "x_test = x_test.reshape((nb_samples_test, 28 * 28))\n",
        "\n",
        "# Step 2: Create the model\n",
        "\n",
        "model = SVC(C=1.0, kernel=\"rbf\")\n",
        "\n",
        "# Step 3: Create the ART classifier\n",
        "\n",
        "classifier = SklearnClassifier(model=model, clip_values=(min_pixel_value, max_pixel_value))\n",
        "\n",
        "# Step 4: Train the ART classifier\n",
        "\n",
        "classifier.fit(x_train, y_train)\n",
        "\n",
        "# Step 5: Evaluate the ART classifier on benign test examples\n",
        "\n",
        "predictions = classifier.predict(x_test)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))\n",
        "\n",
        "# Step 6: Generate adversarial test examples\n",
        "attack = FastGradientMethod(estimator=classifier, eps=0.2)\n",
        "x_test_adv = attack.generate(x=x_test)\n",
        "\n",
        "# Step 7: Evaluate the ART classifier on adversarial test examples\n",
        "\n",
        "predictions = classifier.predict(x_test_adv)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "print(\"Accuracy on adversarial test examples: {}%\".format(accuracy * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnVPRX4EW0wO",
        "outputId": "00f38d7f-92d7-480c-eef3-f6abdf84b4d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:art.estimators.scikitlearn:Input shape not recognised. The model might not have been fitted.\n",
            "WARNING:art.estimators.classification.scikitlearn:Number of classes not recognised. The model might not have been fitted.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on benign test examples: 97.92%\n",
            "Accuracy on adversarial test examples: 58.74%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "The script demonstrates a simple example of using ART with XGBoost. The example train a small model on the MNIST dataset\n",
        "and creates adversarial examples using the Zeroth Order Optimization attack. Here we provide a pretrained model to the\n",
        "ART classifier.\n",
        "The parameters are chosen for reduced computational requirements of the script and not optimised for accuracy.\n",
        "\"\"\"\n",
        "\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "\n",
        "from art.attacks.evasion import ZooAttack\n",
        "from art.estimators.classification import XGBoostClassifier\n",
        "from art.utils import load_mnist\n",
        "\n",
        "# Step 1: Load the MNIST dataset\n",
        "\n",
        "(x_train, y_train), (x_test, y_test), min_pixel_value, max_pixel_value = load_mnist()\n",
        "\n",
        "# Step 1a: Flatten dataset\n",
        "\n",
        "x_test = x_test[0:5]\n",
        "y_test = y_test[0:5]\n",
        "\n",
        "nb_samples_train = x_train.shape[0]\n",
        "nb_samples_test = x_test.shape[0]\n",
        "x_train = x_train.reshape((nb_samples_train, 28 * 28))\n",
        "x_test = x_test.reshape((nb_samples_test, 28 * 28))\n",
        "\n",
        "# Step 2: Create the model\n",
        "\n",
        "params = {\"objective\": \"multi:softprob\", \"eval_metric\": [\"mlogloss\", \"merror\"], \"num_class\": 10}\n",
        "dtrain = xgb.DMatrix(x_train, label=np.argmax(y_train, axis=1))\n",
        "dtest = xgb.DMatrix(x_test, label=np.argmax(y_test, axis=1))\n",
        "evals = [(dtest, \"test\"), (dtrain, \"train\")]\n",
        "model = xgb.train(params=params, dtrain=dtrain, num_boost_round=2, evals=evals)\n",
        "\n",
        "# Step 3: Create the ART classifier\n",
        "\n",
        "classifier = XGBoostClassifier(\n",
        "    model=model, clip_values=(min_pixel_value, max_pixel_value), nb_features=28 * 28, nb_classes=10\n",
        ")\n",
        "\n",
        "# Step 4: Train the ART classifier\n",
        "\n",
        "# The model has already been trained in step 2\n",
        "\n",
        "# Step 5: Evaluate the ART classifier on benign test examples\n",
        "\n",
        "predictions = classifier.predict(x_test)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))\n",
        "\n",
        "# Step 6: Generate adversarial test examples\n",
        "attack = ZooAttack(\n",
        "    classifier=classifier,\n",
        "    confidence=0.0,\n",
        "    targeted=False,\n",
        "    learning_rate=1e-1,\n",
        "    max_iter=200,\n",
        "    binary_search_steps=10,\n",
        "    initial_const=1e-3,\n",
        "    abort_early=True,\n",
        "    use_resize=False,\n",
        "    use_importance=False,\n",
        "    nb_parallel=5,\n",
        "    batch_size=1,\n",
        "    variable_h=0.01,\n",
        ")\n",
        "x_test_adv = attack.generate(x=x_test, y=y_test)\n",
        "\n",
        "# Step 7: Evaluate the ART classifier on adversarial test examples\n",
        "\n",
        "predictions = classifier.predict(x_test_adv)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "print(\"Accuracy on adversarial test examples: {}%\".format(accuracy * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "51903c50089b48aaa059503816116341",
            "9bb2c8ad7040458e8f680e1a3227782c",
            "c2393ec16a6a421ebc20337d3181a039",
            "3f4b344b1e2148e29838b5279cecc2cf",
            "75c4eaf5824946e09f91eec6d7b3d2d7",
            "acfd8c6082de4e4fa22ccdeb4a07fb15",
            "0e36ca1085db45dab5a50e56c9e1ee51",
            "2627a22961a6479ba7e78bc71698f34a",
            "583b0df0876041b0a13461416db9f4fb",
            "1850a6441fa74836a242b9829a8fd7f0",
            "36e2ad37f91a473982add3124a13d769"
          ]
        },
        "id": "fZjB0JBiZL5P",
        "outputId": "5d015624-cb5e-4b07-cba8-2a8574bf9529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\ttest-mlogloss:1.08678\ttest-merror:0.00000\ttrain-mlogloss:1.35689\ttrain-merror:0.13210\n",
            "[1]\ttest-mlogloss:0.80412\ttest-merror:0.00000\ttrain-mlogloss:1.02601\ttrain-merror:0.09192\n",
            "Accuracy on benign test examples: 100.0%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ZOO:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51903c50089b48aaa059503816116341"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on adversarial test examples: 0.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MIT License\n",
        "#\n",
        "# Copyright (C) The Adversarial Robustness Toolbox (ART) Authors 2020\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated\n",
        "# documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the\n",
        "# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit\n",
        "# persons to whom the Software is furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in all copies or substantial portions of the\n",
        "# Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE\n",
        "# WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\n",
        "# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "# SOFTWARE.\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import argparse\n",
        "import json\n",
        "import yaml\n",
        "import pprint\n",
        "\n",
        "from art.estimators.object_detection import PyTorchFasterRCNN\n",
        "from art.attacks.evasion import RobustDPatch\n",
        "\n",
        "\n",
        "COCO_INSTANCE_CATEGORY_NAMES = [\n",
        "    \"__background__\",\n",
        "    \"person\",\n",
        "    \"bicycle\",\n",
        "    \"car\",\n",
        "    \"motorcycle\",\n",
        "    \"airplane\",\n",
        "    \"bus\",\n",
        "    \"train\",\n",
        "    \"truck\",\n",
        "    \"boat\",\n",
        "    \"traffic light\",\n",
        "    \"fire hydrant\",\n",
        "    \"N/A\",\n",
        "    \"stop sign\",\n",
        "    \"parking meter\",\n",
        "    \"bench\",\n",
        "    \"bird\",\n",
        "    \"cat\",\n",
        "    \"dog\",\n",
        "    \"horse\",\n",
        "    \"sheep\",\n",
        "    \"cow\",\n",
        "    \"elephant\",\n",
        "    \"bear\",\n",
        "    \"zebra\",\n",
        "    \"giraffe\",\n",
        "    \"N/A\",\n",
        "    \"backpack\",\n",
        "    \"umbrella\",\n",
        "    \"N/A\",\n",
        "    \"N/A\",\n",
        "    \"handbag\",\n",
        "    \"tie\",\n",
        "    \"suitcase\",\n",
        "    \"frisbee\",\n",
        "    \"skis\",\n",
        "    \"snowboard\",\n",
        "    \"sports ball\",\n",
        "    \"kite\",\n",
        "    \"baseball bat\",\n",
        "    \"baseball glove\",\n",
        "    \"skateboard\",\n",
        "    \"surfboard\",\n",
        "    \"tennis racket\",\n",
        "    \"bottle\",\n",
        "    \"N/A\",\n",
        "    \"wine glass\",\n",
        "    \"cup\",\n",
        "    \"fork\",\n",
        "    \"knife\",\n",
        "    \"spoon\",\n",
        "    \"bowl\",\n",
        "    \"banana\",\n",
        "    \"apple\",\n",
        "    \"sandwich\",\n",
        "    \"orange\",\n",
        "    \"broccoli\",\n",
        "    \"carrot\",\n",
        "    \"hot dog\",\n",
        "    \"pizza\",\n",
        "    \"donut\",\n",
        "    \"cake\",\n",
        "    \"chair\",\n",
        "    \"couch\",\n",
        "    \"potted plant\",\n",
        "    \"bed\",\n",
        "    \"N/A\",\n",
        "    \"dining table\",\n",
        "    \"N/A\",\n",
        "    \"N/A\",\n",
        "    \"toilet\",\n",
        "    \"N/A\",\n",
        "    \"tv\",\n",
        "    \"laptop\",\n",
        "    \"mouse\",\n",
        "    \"remote\",\n",
        "    \"keyboard\",\n",
        "    \"cell phone\",\n",
        "    \"microwave\",\n",
        "    \"oven\",\n",
        "    \"toaster\",\n",
        "    \"sink\",\n",
        "    \"refrigerator\",\n",
        "    \"N/A\",\n",
        "    \"book\",\n",
        "    \"clock\",\n",
        "    \"vase\",\n",
        "    \"scissors\",\n",
        "    \"teddy bear\",\n",
        "    \"hair drier\",\n",
        "    \"toothbrush\",\n",
        "]\n",
        "\n",
        "\n",
        "def extract_predictions(predictions_):\n",
        "\n",
        "    # for key, item in predictions[0].items():\n",
        "    #     print(key, item)\n",
        "\n",
        "    # Get the predicted class\n",
        "    predictions_class = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in list(predictions_[\"labels\"])]\n",
        "    print(\"\\npredicted classes:\", predictions_class)\n",
        "\n",
        "    # Get the predicted bounding boxes\n",
        "    predictions_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(predictions_[\"boxes\"])]\n",
        "\n",
        "    # Get the predicted prediction score\n",
        "    predictions_score = list(predictions_[\"scores\"])\n",
        "    print(\"predicted score:\", predictions_score)\n",
        "\n",
        "    # Get a list of index with score greater than threshold\n",
        "    threshold = 0.5\n",
        "    predictions_t = [predictions_score.index(x) for x in predictions_score if x > threshold][-1]\n",
        "\n",
        "    predictions_boxes = predictions_boxes[: predictions_t + 1]\n",
        "    predictions_class = predictions_class[: predictions_t + 1]\n",
        "\n",
        "    return predictions_class, predictions_boxes, predictions_class\n",
        "\n",
        "\n",
        "def plot_image_with_boxes(img, boxes, pred_cls):\n",
        "    text_size = 5\n",
        "    text_th = 5\n",
        "    rect_th = 6\n",
        "\n",
        "    for i in range(len(boxes)):\n",
        "        # Draw Rectangle with the coordinates\n",
        "\n",
        "        cv2.rectangle(\n",
        "            img,\n",
        "            (int(boxes[i][0][0]), int(boxes[i][0][1])),\n",
        "            (int(boxes[i][1][0]), int(boxes[i][1][1])),\n",
        "            color=(0, 255, 0),\n",
        "            thickness=rect_th,\n",
        "        )\n",
        "        # Write the prediction class\n",
        "        cv2.putText(\n",
        "            img,\n",
        "            pred_cls[i],\n",
        "            (int(boxes[i][0][0]), int(boxes[i][0][1])),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX,\n",
        "            text_size,\n",
        "            (0, 255, 0),\n",
        "            thickness=text_th,\n",
        "        )\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.astype(np.uint8), interpolation=\"nearest\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def get_loss(frcnn, x, y):\n",
        "    frcnn._model.train()\n",
        "    transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
        "    image_tensor_list = list()\n",
        "\n",
        "    for i in range(x.shape[0]):\n",
        "        if frcnn.clip_values is not None:\n",
        "            img = transform(x[i] / frcnn.clip_values[1]).to(frcnn._device)\n",
        "        else:\n",
        "            img = transform(x[i]).to(frcnn._device)\n",
        "        image_tensor_list.append(img)\n",
        "\n",
        "    loss = frcnn._model(image_tensor_list, y)\n",
        "    for loss_type in [\"loss_classifier\", \"loss_box_reg\", \"loss_objectness\", \"loss_rpn_box_reg\"]:\n",
        "        loss[loss_type] = loss[loss_type].cpu().detach().numpy().item()\n",
        "    return loss\n",
        "\n",
        "\n",
        "def append_loss_history(loss_history, output):\n",
        "    for loss in [\"loss_classifier\", \"loss_box_reg\", \"loss_objectness\", \"loss_rpn_box_reg\"]:\n",
        "        loss_history[loss] += [output[loss]]\n",
        "    return loss_history\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--config\", required=False, default=None, help=\"Path of config yaml file\")\n",
        "    cmdline = parser.parse_args()\n",
        "\n",
        "    if cmdline.config and os.path.exists(cmdline.config):\n",
        "        with open(cmdline.config, \"r\") as cf:\n",
        "            config = yaml.safe_load(cf.read())\n",
        "    else:\n",
        "        config = {\n",
        "            \"attack_losses\": [\"loss_classifier\", \"loss_box_reg\", \"loss_objectness\", \"loss_rpn_box_reg\"],\n",
        "            \"cuda_visible_devices\": \"1\",\n",
        "            \"patch_shape\": [450, 450, 3],\n",
        "            \"patch_location\": [600, 750],\n",
        "            \"crop_range\": [0, 0],\n",
        "            \"brightness_range\": [1.0, 1.0],\n",
        "            \"rotation_weights\": [1, 0, 0, 0],\n",
        "            \"sample_size\": 1,\n",
        "            \"learning_rate\": 1.0,\n",
        "            \"max_iter\": 5000,\n",
        "            \"batch_size\": 1,\n",
        "            \"image_file\": \"banner-diverse-group-of-people-2.jpg\",\n",
        "            \"resume\": False,\n",
        "            \"path\": \"\",\n",
        "        }\n",
        "\n",
        "    pp = pprint.PrettyPrinter(indent=4)\n",
        "    pp.pprint(config)\n",
        "\n",
        "    if config[\"cuda_visible_devices\"] is None:\n",
        "        device_type = \"cpu\"\n",
        "    else:\n",
        "        device_type = \"gpu\"\n",
        "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = config[\"cuda_visible_devices\"]\n",
        "\n",
        "    frcnn = PyTorchFasterRCNN(\n",
        "        clip_values=(0, 255), channels_first=False, attack_losses=config[\"attack_losses\"], device_type=device_type\n",
        "    )\n",
        "\n",
        "    image_1 = cv2.imread(config[\"image_file\"])\n",
        "    image_1 = cv2.cvtColor(image_1, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
        "    image_1 = cv2.resize(image_1, dsize=(image_1.shape[1], image_1.shape[0]), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    image = np.stack([image_1], axis=0).astype(np.float32)\n",
        "\n",
        "    attack = RobustDPatch(\n",
        "        frcnn,\n",
        "        patch_shape=config[\"patch_shape\"],\n",
        "        patch_location=config[\"patch_location\"],\n",
        "        crop_range=config[\"crop_range\"],\n",
        "        brightness_range=config[\"brightness_range\"],\n",
        "        rotation_weights=config[\"rotation_weights\"],\n",
        "        sample_size=config[\"sample_size\"],\n",
        "        learning_rate=config[\"learning_rate\"],\n",
        "        max_iter=1,\n",
        "        batch_size=config[\"batch_size\"],\n",
        "    )\n",
        "\n",
        "    x = image.copy()\n",
        "\n",
        "    y = frcnn.predict(x=x)\n",
        "    for i, y_i in enumerate(y):\n",
        "        y[i][\"boxes\"] = torch.from_numpy(y_i[\"boxes\"]).type(torch.float).to(frcnn._device)\n",
        "        y[i][\"labels\"] = torch.from_numpy(y_i[\"labels\"]).type(torch.int64).to(frcnn._device)\n",
        "        y[i][\"scores\"] = torch.from_numpy(y_i[\"scores\"]).to(frcnn._device)\n",
        "\n",
        "    if config[\"resume\"]:\n",
        "        patch = np.load(os.path.join(config[\"path\"], \"patch.npy\"))\n",
        "        attack._patch = patch\n",
        "\n",
        "        with open(os.path.join(config[\"path\"], \"loss_history.json\"), \"r\") as file:\n",
        "            loss_history = json.load(file)\n",
        "    else:\n",
        "        loss_history = {\"loss_classifier\": [], \"loss_box_reg\": [], \"loss_objectness\": [], \"loss_rpn_box_reg\": []}\n",
        "\n",
        "    for i in range(config[\"max_iter\"]):\n",
        "        print(\"Iteration:\", i)\n",
        "        patch = attack.generate(x)\n",
        "        x_patch = attack.apply_patch(x)\n",
        "\n",
        "        loss = get_loss(frcnn, x_patch, y)\n",
        "        print(loss)\n",
        "        loss_history = append_loss_history(loss_history, loss)\n",
        "\n",
        "        with open(os.path.join(config[\"path\"], \"loss_history.json\"), \"w\") as file:\n",
        "            file.write(json.dumps(loss_history))\n",
        "\n",
        "        np.save(os.path.join(config[\"path\"], \"patch\"), attack._patch)\n",
        "\n",
        "    predictions_adv = frcnn.predict(x=x_patch)\n",
        "\n",
        "    for i in range(image.shape[0]):\n",
        "        print(\"\\nPredictions adversarial image {}:\".format(i))\n",
        "\n",
        "        # Process predictions\n",
        "        predictions_adv_class, predictions_adv_boxes, predictions_adv_class = extract_predictions(predictions_adv[i])\n",
        "\n",
        "        # Plot predictions\n",
        "        plot_image_with_boxes(img=x_patch[i].copy(), boxes=predictions_adv_boxes, pred_cls=predictions_adv_class)"
      ],
      "metadata": {
        "id": "yS_JyIMWZk6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Hyperparameters\n",
        "time_steps = 5  # Number of time steps in the sequence\n",
        "input_dim = 3   # Input features\n",
        "hidden_units = 4  # Number of hidden units\n",
        "output_dim = 2  # Output features\n",
        "learning_rate = 0.01\n",
        "# Initialize weights and biases for the RNN manually\n",
        "Wx = tf.Variable(tf.random.normal([input_dim, hidden_units]))  # Input-to-hidden weights\n",
        "Wh = tf.Variable(tf.random.normal([hidden_units, hidden_units]))  # Hidden-to-hidden weights\n",
        "Wy = tf.Variable(tf.random.normal([hidden_units, output_dim]))  # Hidden-to-output weights\n",
        "bh = tf.Variable(tf.zeros([hidden_units]))  # Hidden bias\n",
        "by = tf.Variable(tf.zeros([output_dim]))  # Output bias\n",
        "\n",
        "# Dummy data (batch size = 1 for simplicity)\n",
        "X = tf.random.normal([1, time_steps, input_dim])  # Input sequence\n",
        "Y_true = tf.random.normal([1, time_steps, output_dim])  # Ground truth outputs\n",
        "\n",
        "# Training step with manual BPTT\n",
        "def train_step(X, Y_true):\n",
        "    batch_size = X.shape[0]\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Forward pass\n",
        "        h_t = tf.zeros([batch_size, hidden_units])  # Initial hidden state\n",
        "        outputs = []\n",
        "        for t in range(time_steps):\n",
        "            x_t = X[:, t, :]  # Input at time step t\n",
        "            h_t = tf.nn.tanh(tf.matmul(x_t, Wx) + tf.matmul(h_t, Wh) + bh)  # Hidden state update\n",
        "            y_t = tf.matmul(h_t, Wy) + by  # Output at time step t\n",
        "            outputs.append(y_t)\n",
        "\n",
        "        outputs = tf.stack(outputs, axis=1)  # Shape: [batch_size, time_steps, output_dim]\n",
        "        loss = tf.reduce_mean(tf.square(outputs - Y_true))  # Mean squared error\n",
        "\n",
        "    # Backward pass (BPTT)\n",
        "    gradients = tape.gradient(loss, [Wx, Wh, Wy, bh, by])\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "    optimizer.apply_gradients(zip(gradients, [Wx, Wh, Wy, bh, by]))\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Training loop\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    loss = train_step(X, Y_true)\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.numpy()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ohC73GVBcM7",
        "outputId": "77dff623-5491-4ad4-c2c9-77601d0d6372"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 4.674145698547363\n",
            "Epoch 10, Loss: 3.146674156188965\n",
            "Epoch 20, Loss: 2.2044918537139893\n",
            "Epoch 30, Loss: 1.4331787824630737\n",
            "Epoch 40, Loss: 1.0548491477966309\n",
            "Epoch 50, Loss: 0.7887776494026184\n",
            "Epoch 60, Loss: 0.5761017203330994\n",
            "Epoch 70, Loss: 0.40344104170799255\n",
            "Epoch 80, Loss: 0.26267001032829285\n",
            "Epoch 90, Loss: 0.15752963721752167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the variable\n",
        "x = tf.Variable(3.0)\n",
        "\n",
        "# Compute higher-order gradient\n",
        "with tf.GradientTape() as outer_tape:\n",
        "    with tf.GradientTape() as inner_tape:\n",
        "        y = x**3  # Compute y = x^3\n",
        "    dy_dx = inner_tape.gradient(y, x)  # First derivative: 3x^2\n",
        "d2y_dx2 = outer_tape.gradient(dy_dx, x)  # Second derivative: 6x\n",
        "\n",
        "print(\"First derivative:\", dy_dx.numpy())\n",
        "print(\"Second derivative:\", d2y_dx2.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHTf0lKTDAqL",
        "outputId": "fbd9b0b4-aa82-4282-ccf3-eec152e8a2c9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First derivative: 27.0\n",
            "Second derivative: 18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom model\n",
        "class SimpleModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(SimpleModel, self).__init__()\n",
        "        self.dense = tf.keras.layers.Dense(1, activation='linear')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.dense(inputs)\n",
        "\n",
        "# Create the model and input\n",
        "model = SimpleModel()\n",
        "x = tf.constant([[1.0, 2.0, 3.0]])\n",
        "y_true = tf.constant([[4.0]])\n",
        "\n",
        "# Compute gradients for trainable parameters\n",
        "with tf.GradientTape() as tape:\n",
        "    y_pred = model(x)\n",
        "    loss = tf.reduce_mean((y_pred - y_true)**2)  # MSE loss\n",
        "\n",
        "# Compute gradients\n",
        "gradients = tape.gradient(loss, model.trainable_variables)\n",
        "for var, grad in zip(model.trainable_variables, gradients):\n",
        "    print(f\"Gradient for {var.name}:\", grad.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-SRK8FGDTnD",
        "outputId": "c2a94c0c-f238-4c1f-9c40-5b838d8076c2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient for kernel: [[1.5743093]\n",
            " [3.1486187]\n",
            " [4.722928 ]]\n",
            "Gradient for bias: [1.5743093]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define variables\n",
        "x = tf.Variable(1.0)\n",
        "y = tf.Variable(2.0)\n",
        "\n",
        "# Compute gradient\n",
        "with tf.GradientTape() as tape:\n",
        "    z = x**2 + y**3 + 3*x*y  # Multivariable function\n",
        "\n",
        "# Compute gradients\n",
        "gradients = tape.gradient(z, [x, y])\n",
        "print(\"Gradient w.r.t x:\", gradients[0].numpy())\n",
        "print(\"Gradient w.r.t y:\", gradients[1].numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L63gGdO2Dg9M",
        "outputId": "beff26f5-6b11-4b50-a77b-f575f698d953"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient w.r.t x: 8.0\n",
            "Gradient w.r.t y: 15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the variable\n",
        "x = tf.Variable(-3.0)\n",
        "\n",
        "# Compute gradient\n",
        "with tf.GradientTape() as tape:\n",
        "    y = tf.nn.relu(x)\n",
        "\n",
        "gradient = tape.gradient(y, x)\n",
        "print(\"Gradient of ReLU:\", gradient.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlkAUwjYEPFS",
        "outputId": "b6963866-db0d-4a77-e0e7-4a59dad6c8a4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient of ReLU: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define logits\n",
        "logits = tf.Variable([1.0, 2.0, 3.0])\n",
        "\n",
        "# Compute softmax and its gradient\n",
        "with tf.GradientTape() as tape:\n",
        "    probs = tf.nn.softmax(logits)\n",
        "\n",
        "gradient = tape.gradient(probs, logits)\n",
        "print(\"Gradient of Softmax:\", gradient.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNmDP4WSETp_",
        "outputId": "f4bb189c-f451-4bf3-822d-6e739162271c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient of Softmax: [5.3662399e-09 1.4586954e-08 3.9651447e-08]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input data\n",
        "x = tf.constant([[1.0, 2.0]])\n",
        "y_true = tf.constant([[0.5]])\n",
        "\n",
        "# Weights and biases\n",
        "W = tf.Variable([[0.1, 0.2], [0.3, 0.4]])\n",
        "b = tf.Variable([[0.1, 0.2]])\n",
        "\n",
        "# Compute loss and gradients\n",
        "with tf.GradientTape() as tape:\n",
        "    z = tf.matmul(x, W) + b  # Linear transformation\n",
        "    y_pred = tf.nn.sigmoid(z)  # Sigmoid activation\n",
        "    loss = tf.reduce_mean(0.5 * tf.square(y_pred - y_true))  # Mean squared error\n",
        "\n",
        "# Compute gradients\n",
        "gradients = tape.gradient(loss, [W, b])\n",
        "print(\"Gradient for W:\", gradients[0].numpy())\n",
        "print(\"Gradient for b:\", gradients[1].numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnTAirmlEoNV",
        "outputId": "8f4cfa0b-c5be-4d2b-f0fe-a90cfea26953"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient for W: [[0.02031869 0.02388453]\n",
            " [0.04063738 0.04776907]]\n",
            "Gradient for b: [[0.02031869 0.02388453]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the variable\n",
        "x = tf.Variable(3.0)\n",
        "\n",
        "# Compute gradient\n",
        "with tf.GradientTape() as tape:\n",
        "    y = tf.sin(x**2 + 2*x)  # Composite function\n",
        "\n",
        "# Compute gradient\n",
        "gradient = tape.gradient(y, x)\n",
        "print(\"Gradient of f(x):\", gradient.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZq5ladUEvxv",
        "outputId": "735d9a98-3b14-400d-b2e1-faae7113715b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient of f(x): -6.077503\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the variable\n",
        "x = tf.Variable(2.0)\n",
        "\n",
        "# Compute gradient using GradientTape\n",
        "with tf.GradientTape() as tape:\n",
        "    y = x**2 + 3*x + 5  # Quadratic function\n",
        "\n",
        "# Compute gradient\n",
        "gradient = tape.gradient(y, x)\n",
        "print(\"Gradient of f(x):\", gradient.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hcd55yjE2bu",
        "outputId": "7a48bd46-ceb9-4806-b75b-4c74e43c7286"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient of f(x): 7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense\n",
        "import numpy as np\n",
        "\n",
        "# Generate sample sequential data\n",
        "# For simplicity, let's create a toy dataset of a sine wave\n",
        "def generate_time_series(batch_size, time_steps):\n",
        "    freq = np.random.uniform(0.1, 0.5, size=(batch_size, 1))\n",
        "    phase = np.random.uniform(0, 2 * np.pi, size=(batch_size, 1))\n",
        "    t = np.linspace(0, 1, time_steps)\n",
        "    X = np.sin(2 * np.pi * freq * t + phase)\n",
        "    y = np.cos(2 * np.pi * freq * t + phase)\n",
        "    return X[..., np.newaxis], y[..., np.newaxis]  # Add an extra dimension for the feature\n",
        "\n",
        "# Generate training and validation data\n",
        "batch_size = 64\n",
        "time_steps = 50\n",
        "input_dim = 1\n",
        "output_dim = 1\n",
        "\n",
        "X_train, y_train = generate_time_series(batch_size, time_steps)\n",
        "X_val, y_val = generate_time_series(batch_size, time_steps)\n",
        "\n",
        "# Define the GRU model\n",
        "model = Sequential([\n",
        "    GRU(64, return_sequences=True, input_shape=(time_steps, input_dim)),  # GRU with 64 units\n",
        "    Dense(output_dim)  # Fully connected layer to produce output\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=batch_size)\n",
        "\n",
        "# Predict on new data\n",
        "X_test, y_test = generate_time_series(batch_size, time_steps)\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "print(\"Sample prediction:\", predictions[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bro1v82jJUJN",
        "outputId": "24e9e54f-a956-49fe-9ad4-29512dfde662"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.4696 - mae: 0.6127 - val_loss: 0.4960 - val_mae: 0.6352\n",
            "Epoch 2/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4621 - mae: 0.6082 - val_loss: 0.4959 - val_mae: 0.6351\n",
            "Epoch 3/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.4553 - mae: 0.6038 - val_loss: 0.4965 - val_mae: 0.6352\n",
            "Epoch 4/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4490 - mae: 0.5995 - val_loss: 0.4977 - val_mae: 0.6356\n",
            "Epoch 5/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.4432 - mae: 0.5953 - val_loss: 0.4995 - val_mae: 0.6362\n",
            "Epoch 6/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.4380 - mae: 0.5912 - val_loss: 0.5018 - val_mae: 0.6369\n",
            "Epoch 7/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.4332 - mae: 0.5872 - val_loss: 0.5044 - val_mae: 0.6376\n",
            "Epoch 8/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4288 - mae: 0.5833 - val_loss: 0.5074 - val_mae: 0.6385\n",
            "Epoch 9/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.4249 - mae: 0.5796 - val_loss: 0.5104 - val_mae: 0.6392\n",
            "Epoch 10/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - loss: 0.4214 - mae: 0.5759 - val_loss: 0.5132 - val_mae: 0.6397\n",
            "Epoch 11/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4181 - mae: 0.5723 - val_loss: 0.5156 - val_mae: 0.6399\n",
            "Epoch 12/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.4149 - mae: 0.5687 - val_loss: 0.5171 - val_mae: 0.6397\n",
            "Epoch 13/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.4118 - mae: 0.5653 - val_loss: 0.5174 - val_mae: 0.6387\n",
            "Epoch 14/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.4085 - mae: 0.5618 - val_loss: 0.5160 - val_mae: 0.6369\n",
            "Epoch 15/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4047 - mae: 0.5583 - val_loss: 0.5127 - val_mae: 0.6341\n",
            "Epoch 16/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4004 - mae: 0.5547 - val_loss: 0.5071 - val_mae: 0.6300\n",
            "Epoch 17/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3952 - mae: 0.5510 - val_loss: 0.4992 - val_mae: 0.6247\n",
            "Epoch 18/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3892 - mae: 0.5471 - val_loss: 0.4889 - val_mae: 0.6180\n",
            "Epoch 19/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.3823 - mae: 0.5429 - val_loss: 0.4762 - val_mae: 0.6098\n",
            "Epoch 20/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.3744 - mae: 0.5384 - val_loss: 0.4611 - val_mae: 0.6000\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Sample prediction: [[ 0.2032015 ]\n",
            " [ 0.3104612 ]\n",
            " [ 0.35374212]\n",
            " [ 0.35657826]\n",
            " [ 0.33706924]\n",
            " [ 0.30712038]\n",
            " [ 0.27381298]\n",
            " [ 0.24098118]\n",
            " [ 0.21045725]\n",
            " [ 0.18292283]\n",
            " [ 0.1584467 ]\n",
            " [ 0.13680504]\n",
            " [ 0.11766095]\n",
            " [ 0.10065994]\n",
            " [ 0.08547464]\n",
            " [ 0.07182312]\n",
            " [ 0.05947199]\n",
            " [ 0.04823336]\n",
            " [ 0.0379585 ]\n",
            " [ 0.02853129]\n",
            " [ 0.01986186]\n",
            " [ 0.01188136]\n",
            " [ 0.00453731]\n",
            " [-0.00220997]\n",
            " [-0.0083902 ]\n",
            " [-0.01402542]\n",
            " [-0.01913174]\n",
            " [-0.02372075]\n",
            " [-0.02780058]\n",
            " [-0.03137675]\n",
            " [-0.03445275]\n",
            " [-0.03703076]\n",
            " [-0.03911196]\n",
            " [-0.0406969 ]\n",
            " [-0.04178591]\n",
            " [-0.04237914]\n",
            " [-0.04247706]\n",
            " [-0.04208048]\n",
            " [-0.04119085]\n",
            " [-0.03981047]\n",
            " [-0.03794252]\n",
            " [-0.0355914 ]\n",
            " [-0.0327628 ]\n",
            " [-0.0294638 ]\n",
            " [-0.0257031 ]\n",
            " [-0.02149113]\n",
            " [-0.01684   ]\n",
            " [-0.01176376]\n",
            " [-0.00627838]\n",
            " [-0.00040166]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "import numpy as np\n",
        "\n",
        "# Generate sample sequential data\n",
        "def generate_time_series(batch_size, time_steps):\n",
        "    freq = np.random.uniform(0.1, 0.5, size=(batch_size, 1))\n",
        "    phase = np.random.uniform(0, 2 * np.pi, size=(batch_size, 1))\n",
        "    t = np.linspace(0, 1, time_steps)\n",
        "    X = np.sin(2 * np.pi * freq * t + phase)\n",
        "    y = np.cos(2 * np.pi * freq * t + phase)\n",
        "    return X[..., np.newaxis], y[..., np.newaxis]\n",
        "\n",
        "# Generate training and validation data\n",
        "batch_size = 64\n",
        "time_steps = 50\n",
        "input_dim = 1\n",
        "output_dim = 1\n",
        "\n",
        "X_train, y_train = generate_time_series(batch_size, time_steps)\n",
        "X_val, y_val = generate_time_series(batch_size, time_steps)\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(64, return_sequences=True, input_shape=(time_steps, input_dim)),  # LSTM with 64 units\n",
        "    Dense(output_dim)  # Fully connected layer to produce output\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=batch_size)\n",
        "\n",
        "# Predict on new data\n",
        "X_test, y_test = generate_time_series(batch_size, time_steps)\n",
        "print(X_test)\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "print(\"Sample prediction LSTM:\", predictions[0])\n",
        "\n",
        "print(\"GRU Sample Prediction\")\n",
        "\n",
        "#\n",
        "# Define the GRU model\n",
        "model2 = Sequential([\n",
        "    GRU(64, return_sequences=True, input_shape=(time_steps, input_dim)),  # GRU with 64 units\n",
        "    Dense(output_dim)  # Fully connected layer to produce output\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model2.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "model2.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=batch_size)\n",
        "print(X_test)\n",
        "predictions = model2.predict(X_test)\n",
        "\n",
        "print(\"Sample prediction GRU:\", predictions[0])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xbrMpSFKTUj",
        "outputId": "b860ade1-f00e-4c44-d5b9-b2d29a044348"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4576 - mae: 0.6056 - val_loss: 0.4770 - val_mae: 0.6219\n",
            "Epoch 2/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.4508 - mae: 0.6010 - val_loss: 0.4702 - val_mae: 0.6169\n",
            "Epoch 3/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4448 - mae: 0.5968 - val_loss: 0.4638 - val_mae: 0.6120\n",
            "Epoch 4/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.4391 - mae: 0.5928 - val_loss: 0.4572 - val_mae: 0.6071\n",
            "Epoch 5/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4335 - mae: 0.5887 - val_loss: 0.4502 - val_mae: 0.6016\n",
            "Epoch 6/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.4275 - mae: 0.5843 - val_loss: 0.4421 - val_mae: 0.5954\n",
            "Epoch 7/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - loss: 0.4209 - mae: 0.5794 - val_loss: 0.4328 - val_mae: 0.5881\n",
            "Epoch 8/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.4133 - mae: 0.5737 - val_loss: 0.4219 - val_mae: 0.5795\n",
            "Epoch 9/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.4047 - mae: 0.5672 - val_loss: 0.4095 - val_mae: 0.5694\n",
            "Epoch 10/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3948 - mae: 0.5596 - val_loss: 0.3954 - val_mae: 0.5578\n",
            "Epoch 11/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3838 - mae: 0.5507 - val_loss: 0.3802 - val_mae: 0.5445\n",
            "Epoch 12/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - loss: 0.3717 - mae: 0.5405 - val_loss: 0.3641 - val_mae: 0.5296\n",
            "Epoch 13/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.3588 - mae: 0.5287 - val_loss: 0.3481 - val_mae: 0.5137\n",
            "Epoch 14/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.3453 - mae: 0.5153 - val_loss: 0.3328 - val_mae: 0.4968\n",
            "Epoch 15/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.3316 - mae: 0.5000 - val_loss: 0.3189 - val_mae: 0.4790\n",
            "Epoch 16/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3179 - mae: 0.4829 - val_loss: 0.3072 - val_mae: 0.4613\n",
            "Epoch 17/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.3054 - mae: 0.4664 - val_loss: 0.2984 - val_mae: 0.4475\n",
            "Epoch 18/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.2957 - mae: 0.4541 - val_loss: 0.2927 - val_mae: 0.4413\n",
            "Epoch 19/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.2897 - mae: 0.4468 - val_loss: 0.2901 - val_mae: 0.4410\n",
            "Epoch 20/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.2872 - mae: 0.4448 - val_loss: 0.2903 - val_mae: 0.4438\n",
            "[[[-0.97472326]\n",
            "  [-0.97818187]\n",
            "  [-0.98138874]\n",
            "  ...\n",
            "  [-0.86346846]\n",
            "  [-0.8552657 ]\n",
            "  [-0.84684283]]\n",
            "\n",
            " [[ 0.99628102]\n",
            "  [ 0.99396501]\n",
            "  [ 0.99109315]\n",
            "  ...\n",
            "  [ 0.36445669]\n",
            "  [ 0.34233493]\n",
            "  [ 0.32002172]]\n",
            "\n",
            " [[ 0.6156082 ]\n",
            "  [ 0.59502521]\n",
            "  [ 0.57404432]\n",
            "  ...\n",
            "  [-0.52463421]\n",
            "  [-0.54647209]\n",
            "  [-0.56794453]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.67365291]\n",
            "  [-0.66329577]\n",
            "  [-0.65280999]\n",
            "  ...\n",
            "  [-0.08450698]\n",
            "  [-0.07062282]\n",
            "  [-0.05672497]]\n",
            "\n",
            " [[-0.98000272]\n",
            "  [-0.98474913]\n",
            "  [-0.9888577 ]\n",
            "  ...\n",
            "  [-0.54376954]\n",
            "  [-0.52223642]\n",
            "  [-0.50036503]]\n",
            "\n",
            " [[ 0.9994004 ]\n",
            "  [ 0.99614506]\n",
            "  [ 0.99007074]\n",
            "  ...\n",
            "  [-0.82169219]\n",
            "  [-0.85083728]\n",
            "  [-0.8775746 ]]]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Sample prediction LSTM: [[-0.05463998]\n",
            " [-0.10171818]\n",
            " [-0.13978742]\n",
            " [-0.16761395]\n",
            " [-0.18526906]\n",
            " [-0.19354345]\n",
            " [-0.19358164]\n",
            " [-0.1866554 ]\n",
            " [-0.17402762]\n",
            " [-0.15687647]\n",
            " [-0.13625795]\n",
            " [-0.113092  ]\n",
            " [-0.08816353]\n",
            " [-0.06213063]\n",
            " [-0.03553665]\n",
            " [-0.00882377]\n",
            " [ 0.01765428]\n",
            " [ 0.04361948]\n",
            " [ 0.0688587 ]\n",
            " [ 0.09321372]\n",
            " [ 0.11657247]\n",
            " [ 0.13886145]\n",
            " [ 0.16003895]\n",
            " [ 0.18008918]\n",
            " [ 0.19901736]\n",
            " [ 0.21684504]\n",
            " [ 0.23360664]\n",
            " [ 0.24934587]\n",
            " [ 0.2641136 ]\n",
            " [ 0.27796483]\n",
            " [ 0.29095784]\n",
            " [ 0.30315173]\n",
            " [ 0.3146058 ]\n",
            " [ 0.32537857]\n",
            " [ 0.33552682]\n",
            " [ 0.34510535]\n",
            " [ 0.35416648]\n",
            " [ 0.3627598 ]\n",
            " [ 0.37093213]\n",
            " [ 0.37872738]\n",
            " [ 0.3861865 ]\n",
            " [ 0.39334753]\n",
            " [ 0.40024588]\n",
            " [ 0.4069142 ]\n",
            " [ 0.4133825 ]\n",
            " [ 0.41967866]\n",
            " [ 0.42582786]\n",
            " [ 0.4318535 ]\n",
            " [ 0.43777668]\n",
            " [ 0.44361696]]\n",
            "GRU Sample Prediction\n",
            "Epoch 1/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 0.4741 - mae: 0.6162 - val_loss: 0.5024 - val_mae: 0.6391\n",
            "Epoch 2/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.4713 - mae: 0.6144 - val_loss: 0.5032 - val_mae: 0.6397\n",
            "Epoch 3/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4693 - mae: 0.6129 - val_loss: 0.5038 - val_mae: 0.6400\n",
            "Epoch 4/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.4679 - mae: 0.6117 - val_loss: 0.5040 - val_mae: 0.6400\n",
            "Epoch 5/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - loss: 0.4666 - mae: 0.6105 - val_loss: 0.5034 - val_mae: 0.6394\n",
            "Epoch 6/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4653 - mae: 0.6094 - val_loss: 0.5020 - val_mae: 0.6383\n",
            "Epoch 7/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4639 - mae: 0.6084 - val_loss: 0.4997 - val_mae: 0.6369\n",
            "Epoch 8/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4622 - mae: 0.6074 - val_loss: 0.4970 - val_mae: 0.6352\n",
            "Epoch 9/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4604 - mae: 0.6063 - val_loss: 0.4940 - val_mae: 0.6332\n",
            "Epoch 10/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.4585 - mae: 0.6053 - val_loss: 0.4908 - val_mae: 0.6312\n",
            "Epoch 11/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4567 - mae: 0.6043 - val_loss: 0.4876 - val_mae: 0.6291\n",
            "Epoch 12/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - loss: 0.4547 - mae: 0.6032 - val_loss: 0.4844 - val_mae: 0.6270\n",
            "Epoch 13/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.4528 - mae: 0.6020 - val_loss: 0.4813 - val_mae: 0.6249\n",
            "Epoch 14/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.4507 - mae: 0.6007 - val_loss: 0.4782 - val_mae: 0.6228\n",
            "Epoch 15/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.4484 - mae: 0.5992 - val_loss: 0.4752 - val_mae: 0.6207\n",
            "Epoch 16/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.4459 - mae: 0.5975 - val_loss: 0.4721 - val_mae: 0.6185\n",
            "Epoch 17/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.4432 - mae: 0.5955 - val_loss: 0.4689 - val_mae: 0.6162\n",
            "Epoch 18/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.4401 - mae: 0.5934 - val_loss: 0.4655 - val_mae: 0.6137\n",
            "Epoch 19/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.4368 - mae: 0.5910 - val_loss: 0.4618 - val_mae: 0.6110\n",
            "Epoch 20/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 0.4332 - mae: 0.5883 - val_loss: 0.4575 - val_mae: 0.6078\n",
            "[[[-0.97472326]\n",
            "  [-0.97818187]\n",
            "  [-0.98138874]\n",
            "  ...\n",
            "  [-0.86346846]\n",
            "  [-0.8552657 ]\n",
            "  [-0.84684283]]\n",
            "\n",
            " [[ 0.99628102]\n",
            "  [ 0.99396501]\n",
            "  [ 0.99109315]\n",
            "  ...\n",
            "  [ 0.36445669]\n",
            "  [ 0.34233493]\n",
            "  [ 0.32002172]]\n",
            "\n",
            " [[ 0.6156082 ]\n",
            "  [ 0.59502521]\n",
            "  [ 0.57404432]\n",
            "  ...\n",
            "  [-0.52463421]\n",
            "  [-0.54647209]\n",
            "  [-0.56794453]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.67365291]\n",
            "  [-0.66329577]\n",
            "  [-0.65280999]\n",
            "  ...\n",
            "  [-0.08450698]\n",
            "  [-0.07062282]\n",
            "  [-0.05672497]]\n",
            "\n",
            " [[-0.98000272]\n",
            "  [-0.98474913]\n",
            "  [-0.9888577 ]\n",
            "  ...\n",
            "  [-0.54376954]\n",
            "  [-0.52223642]\n",
            "  [-0.50036503]]\n",
            "\n",
            " [[ 0.9994004 ]\n",
            "  [ 0.99614506]\n",
            "  [ 0.99007074]\n",
            "  ...\n",
            "  [-0.82169219]\n",
            "  [-0.85083728]\n",
            "  [-0.8775746 ]]]\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Sample prediction GRU: [[-0.09094221]\n",
            " [-0.11483897]\n",
            " [-0.09340044]\n",
            " [-0.05101616]\n",
            " [-0.00396323]\n",
            " [ 0.0393173 ]\n",
            " [ 0.07554975]\n",
            " [ 0.10426284]\n",
            " [ 0.1262538 ]\n",
            " [ 0.14273599]\n",
            " [ 0.15492484]\n",
            " [ 0.16387092]\n",
            " [ 0.17041662]\n",
            " [ 0.17520839]\n",
            " [ 0.17872877]\n",
            " [ 0.18133134]\n",
            " [ 0.18327191]\n",
            " [ 0.18473399]\n",
            " [ 0.18584837]\n",
            " [ 0.18670793]\n",
            " [ 0.18737859]\n",
            " [ 0.18790683]\n",
            " [ 0.1883256 ]\n",
            " [ 0.1886581 ]\n",
            " [ 0.1889208 ]\n",
            " [ 0.18912527]\n",
            " [ 0.18927976]\n",
            " [ 0.18939008]\n",
            " [ 0.18946029]\n",
            " [ 0.18949325]\n",
            " [ 0.18949106]\n",
            " [ 0.18945503]\n",
            " [ 0.18938613]\n",
            " [ 0.18928501]\n",
            " [ 0.18915203]\n",
            " [ 0.1889875 ]\n",
            " [ 0.18879154]\n",
            " [ 0.18856414]\n",
            " [ 0.18830527]\n",
            " [ 0.1880149 ]\n",
            " [ 0.18769296]\n",
            " [ 0.18733935]\n",
            " [ 0.18695381]\n",
            " [ 0.18653631]\n",
            " [ 0.1860867 ]\n",
            " [ 0.18560472]\n",
            " [ 0.18509029]\n",
            " [ 0.18454327]\n",
            " [ 0.1839634 ]\n",
            " [ 0.18335062]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **Bidirectional Recurrent Neural Network (BRNN)** is a variation of RNNs that processes sequence data in both forward and backward directions. By using information from both past and future time steps, it achieves a more comprehensive understanding of the sequence compared to standard RNNs, which process data only in the forward direction.\n",
        "\n",
        "---\n",
        "\n",
        "### **How Bidirectional RNN Works**\n",
        "1. **Forward Pass**:\n",
        "   - One RNN processes the sequence from the beginning to the end (forward direction), producing hidden states at each time step.\n",
        "\n",
        "2. **Backward Pass**:\n",
        "   - Another RNN processes the same sequence but in reverse, moving from the end to the beginning (backward direction), producing hidden states for the reverse sequence.\n",
        "\n",
        "3. **Combine Outputs**:\n",
        "   - The outputs from both forward and backward RNNs are combined (concatenated or summed) at each time step, capturing information from both directions.\n",
        "\n",
        "---\n",
        "\n",
        "### **Advantages of Bidirectional RNN**\n",
        "- **Context Awareness**: Incorporates both past and future context, making it ideal for tasks where understanding the entire sequence is critical.\n",
        "- **Improved Accuracy**: Often yields better predictions compared to a unidirectional RNN, especially for applications like language understanding.\n",
        "- **Flexibility**: Can be applied to tasks requiring sequence-level processing (e.g., time-series analysis, speech recognition).\n",
        "\n",
        "---\n",
        "\n",
        "### **Disadvantages**\n",
        "- **Higher Computational Cost**: Requires training two RNNs (forward and backward), doubling the computational overhead.\n",
        "- **Incompatibility with Real-Time Data**: Cannot process data in real-time or streaming scenarios, as the backward pass needs the entire sequence in advance.\n",
        "\n",
        "---\n",
        "\n",
        "### **Applications**\n",
        "Bidirectional RNNs are widely used in tasks like:\n",
        "- **Natural Language Processing** (NLP): Machine translation, sentiment analysis, and named entity recognition.\n",
        "- **Speech Recognition**: To leverage both past and future phonemes in predicting speech outputs.\n",
        "- **Time-Series Prediction**: Forecasting using data trends from both directions.\n",
        "\n",
        "---\n",
        "\n",
        "### **Code Example with TensorFlow/Keras**\n",
        "Here’s how to implement a Bidirectional RNN using TensorFlow/Keras:\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, LSTM, Dense\n",
        "\n",
        "# Define the Bidirectional RNN model\n",
        "model = Sequential([\n",
        "    Bidirectional(LSTM(64, return_sequences=True, input_shape=(50, 1))),  # Bidirectional LSTM\n",
        "    Dense(1)  # Fully connected output layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "This model processes a sequence of data in both forward and backward directions, allowing it to learn patterns from both past and future contexts. Let me know if you'd like a detailed example or help adapting it to your specific task! 😊"
      ],
      "metadata": {
        "id": "A2GxFpI8OOt8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a detailed comparison of **GRU (Gated Recurrent Unit)** and **LSTM (Long Short-Term Memory)**, highlighting their advantages and disadvantages:\n",
        "\n",
        "| **Feature**                | **GRU (Gated Recurrent Unit)**                                        | **LSTM (Long Short-Term Memory)**                                   |\n",
        "|-----------------------------|----------------------------------------------------------------------|----------------------------------------------------------------------|\n",
        "| **Architecture Simplicity** | GRUs are simpler with fewer gates (update and reset), making them faster and easier to implement. | LSTMs have a more complex architecture with three gates (input, forget, and output), which increases computational overhead. |\n",
        "| **Training Speed**          | Faster to train due to fewer parameters.                            | Slower to train as more parameters need to be learned.              |\n",
        "| **Memory Requirements**     | Requires less memory due to fewer parameters.                      | Requires more memory because of additional gates and parameters.    |\n",
        "| **Performance on Small Data** | Performs well, often comparable to LSTM on smaller datasets.       | Can outperform GRUs on small datasets where precise control over memory is essential. |\n",
        "| **Handling Long-Term Dependencies** | Effective for capturing long-term dependencies but slightly less capable compared to LSTM for extremely long sequences. | Superior at handling long-term dependencies due to its sophisticated memory cell mechanism. |\n",
        "| **Suitability for Tasks**   | Well-suited for tasks where computational efficiency is critical, such as real-time systems. | Better for tasks requiring complex temporal relationships, such as language modeling or machine translation. |\n",
        "| **Tuning Complexity**       | Easier to tune due to its simpler design.                          | Requires careful tuning of hyperparameters like forget bias.        |\n",
        "| **Overfitting**             | Lower risk of overfitting as it has fewer parameters.              | Higher risk of overfitting in smaller datasets due to more parameters. |\n",
        "| **Flexibility**             | Slightly less flexible as it lacks as much granular control over memory compared to LSTM. | More flexible and powerful due to its ability to fully control information flow. |\n",
        "\n",
        "---\n",
        "\n",
        "### **Summary**\n",
        "- **Use GRUs** if:\n",
        "  - You prioritize computational efficiency and speed.\n",
        "  - Your dataset is small or real-time processing is critical.\n",
        "\n",
        "- **Use LSTMs** if:\n",
        "  - You need to capture complex, long-term dependencies.\n",
        "  - Your dataset is large and computational resources are not a limiting factor.\n",
        "\n",
        "Both are powerful architectures, and the choice depends on the specific requirements of your task. Let me know if you'd like examples or further guidance! 😊"
      ],
      "metadata": {
        "id": "acGVCJ0EOcUF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here’s how you can implement the same sequential prediction example using an **LSTM** layer instead of a GRU in TensorFlow/Keras.\n",
        "\n",
        "---\n",
        "\n",
        "### **LSTM Implementation Example**\n",
        "LSTMs are a popular choice for processing sequential data as they effectively handle long-term dependencies by using gates to control the flow of information.\n",
        "\n",
        "#### Code Example:\n",
        "```python\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "import numpy as np\n",
        "\n",
        "# Generate sample sequential data\n",
        "def generate_time_series(batch_size, time_steps):\n",
        "    freq = np.random.uniform(0.1, 0.5, size=(batch_size, 1))\n",
        "    phase = np.random.uniform(0, 2 * np.pi, size=(batch_size, 1))\n",
        "    t = np.linspace(0, 1, time_steps)\n",
        "    X = np.sin(2 * np.pi * freq * t + phase)\n",
        "    y = np.cos(2 * np.pi * freq * t + phase)\n",
        "    return X[..., np.newaxis], y[..., np.newaxis]\n",
        "\n",
        "# Generate training and validation data\n",
        "batch_size = 64\n",
        "time_steps = 50\n",
        "input_dim = 1\n",
        "output_dim = 1\n",
        "\n",
        "X_train, y_train = generate_time_series(batch_size, time_steps)\n",
        "X_val, y_val = generate_time_series(batch_size, time_steps)\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(64, return_sequences=True, input_shape=(time_steps, input_dim)),  # LSTM with 64 units\n",
        "    Dense(output_dim)  # Fully connected layer to produce output\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=batch_size)\n",
        "\n",
        "# Predict on new data\n",
        "X_test, y_test = generate_time_series(batch_size, time_steps)\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "print(\"Sample prediction:\", predictions[0])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **Explanation**\n",
        "1. **Data Generation**:\n",
        "   - The same function generates synthetic sequential sine wave data for training, validation, and testing.\n",
        "\n",
        "2. **LSTM Layer**:\n",
        "   - The `LSTM` layer processes sequential data by maintaining long-term memory of the sequence through its gates:\n",
        "     - **Forget Gate**: Decides which information to discard.\n",
        "     - **Input Gate**: Updates the cell state with new information.\n",
        "     - **Output Gate**: Determines the hidden state passed to the next step.\n",
        "   - `return_sequences=True` ensures the LSTM outputs a value for every time step, as needed for sequence-to-sequence tasks.\n",
        "\n",
        "3. **Fully Connected Output Layer**:\n",
        "   - A `Dense` layer maps LSTM's outputs to the desired output dimension (1 in this case).\n",
        "\n",
        "4. **Training**:\n",
        "   - The model is optimized using the Adam optimizer and **mean squared error (MSE)** loss function.\n",
        "\n",
        "5. **Prediction**:\n",
        "   - After training, the model is tested on unseen sequences to generate predictions.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Parameters for LSTM**\n",
        "- **Units (e.g., 64)**:\n",
        "  - Number of hidden units in the LSTM layer. Increasing this value improves capacity but may risk overfitting.\n",
        "- **Return Sequences**:\n",
        "  - Use `True` if the model needs to output predictions for all time steps (sequence-to-sequence tasks).\n",
        "  - Use `False` if only the final output is needed (sequence-to-vector tasks).\n",
        "\n",
        "---\n",
        "\n",
        "This implementation demonstrates how to use an LSTM for sequence prediction. Let me know if you'd like more examples or deeper insights into how LSTMs work! 😊"
      ],
      "metadata": {
        "id": "SMlo6iy8OrsH"
      }
    }
  ]
}